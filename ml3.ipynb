{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    " data = pd.read_csv('norway_new_car_sales_by_make.csv')\n",
    " \n",
    " data['Period'] = data['Year'].astype(str) + '-' + data['Month'].astype(str).str.zfill(2)\n",
    " \n",
    " df = pd.pivot_table(data=data,values='Quantity',index='Make',columns='Period',aggfunc='sum',fill_value=0)\n",
    " return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets(df, x_len=12, y_len=1, test_loops=12):\n",
    " D = df.values\n",
    " rows, periods = D.shape\n",
    " # Training set creation\n",
    " loops = periods + 1- x_len- y_len\n",
    " train = []\n",
    " for col in range(loops):\n",
    "    train.append(D[:,col:col+x_len+y_len])\n",
    " \n",
    " train = np.vstack(train)\n",
    " print(train.shape)\n",
    " X_train, Y_train = np.split(train,[-y_len],axis=1)\n",
    " # Test set creation\n",
    " if test_loops > 0:\n",
    "    X_train, X_test = np.split(X_train,[-rows*test_loops],axis=0)\n",
    "\n",
    "    Y_train, Y_test = np.split(Y_train,[-rows*test_loops],axis=0)\n",
    " else: # No test set: X_test is used to generate the future forecast\n",
    "    X_test = D[:,-x_len:]\n",
    "    Y_test = np.full((X_test.shape[0],y_len),np.nan) #Dummy value\n",
    " # Formatting required for scikit-learn\n",
    " if y_len == 1:\n",
    "    Y_train = Y_train.ravel()\n",
    "    Y_test = Y_test.ravel()\n",
    " return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name=''):\n",
    " df = pd.DataFrame(columns = ['MAE','RMSE','Bias'],index=['Train','Test'])\n",
    " df.index.name = name\n",
    " \n",
    " df.loc['Train','MAE'] = 100*np.mean(abs(Y_train-Y_train_pred))/np.mean(Y_train)\n",
    "\n",
    " df.loc['Train','RMSE'] = 100*np.sqrt(np.mean((Y_train-Y_train_pred)**2))/np.mean(Y_train)\n",
    " \n",
    " df.loc['Train','Bias'] = 100*np.mean((Y_train- Y_train_pred))/np.mean(Y_train)\n",
    "\n",
    " df.loc['Test','MAE'] = 100*np.mean(abs(Y_test- Y_test_pred))/np.mean(Y_test)\n",
    " \n",
    " df.loc['Test','RMSE'] = 100*np.sqrt(np.mean((Y_test-Y_test_pred)**2))/np.mean(Y_test)\n",
    " \n",
    " df.loc['Test','Bias'] = 100*np.mean((Y_test- Y_test_pred))/np.mean(Y_test)\n",
    " df = df.astype(float).round(1) #Round number for display\n",
    " print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7085, 13)\n"
     ]
    }
   ],
   "source": [
    "df = import_data()\n",
    "X_train, Y_train, X_test, Y_test = datasets(df, x_len=12, y_len=1,test_loops=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=8), n_estimators=100, learning_rate=0.25, loss='square')\n",
    "ada = ada.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE  RMSE  Bias\n",
      "AdaBoost                  \n",
      "Train     10.0  21.1  -0.5\n",
      "Test      18.4  48.5   2.1\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = ada.predict(X_train)\n",
    "Y_test_pred = ada.predict(X_test)\n",
    "kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter optimization\n",
    "n_estimators = [100]\n",
    "learning_rate = [0.005,0.01,0.05,0.1,0.15,0.2,0.25,0.3,0.35]\n",
    "loss = ['square','exponential','linear']\n",
    "param_dist = {'n_estimators': n_estimators,'learning_rate': learning_rate,'loss':loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_mae(model, X, Y):\n",
    " Y_pred = model.predict(X)\n",
    " mae = np.mean(np.abs(Y- Y_pred))/np.mean(Y)\n",
    " return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned AdaBoost Parameters: {'n_estimators': 100, 'loss': 'square', 'learning_rate': 0.01}\n",
      "Result: -47.88967219205247\n",
      "Tuned AdaBoost Parameters: {'n_estimators': 100, 'loss': 'linear', 'learning_rate': 0.01}\n",
      "Result: -33.90827547191039\n",
      "Tuned AdaBoost Parameters: {'n_estimators': 100, 'loss': 'linear', 'learning_rate': 0.005}\n",
      "Result: -31.65968371937797\n",
      "Tuned AdaBoost Parameters: {'n_estimators': 100, 'loss': 'square', 'learning_rate': 0.005}\n",
      "Result: -31.475350608064605\n",
      "Tuned AdaBoost Parameters: {'n_estimators': 100, 'loss': 'linear', 'learning_rate': 0.005}\n",
      "Result: -31.67021897136584\n",
      "Tuned AdaBoost Parameters: {'n_estimators': 100, 'loss': 'exponential', 'learning_rate': 0.01}\n",
      "Result: -31.811118698059953\n",
      "Tuned AdaBoost Parameters: {'n_estimators': 100, 'loss': 'exponential', 'learning_rate': 0.005}\n",
      "Result: -31.67195153609393\n",
      "Tuned AdaBoost Parameters: {'n_estimators': 100, 'loss': 'exponential', 'learning_rate': 0.005}\n",
      "Result: -31.680411893036467\n",
      "Score                                                 -31.475351\n",
      "Best Params    {'n_estimators': 100, 'loss': 'square', 'learn...\n",
      "Max Depth                                                      8\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "results = []\n",
    "for max_depth in range(2,18,2):\n",
    " ada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=max_depth))\n",
    " \n",
    " ada_cv = RandomizedSearchCV(ada, param_dist, n_jobs=-1, cv=6, n_iter=20, scoring='neg_mean_absolute_error')\n",
    " ada_cv.fit(X_train,Y_train)\n",
    " print('Tuned AdaBoost Parameters:',ada_cv.best_params_)\n",
    " print('Result:',ada_cv.best_score_)\n",
    "\n",
    " results.append([ada_cv.best_score_,ada_cv.best_params_,max_depth])\n",
    "results = pd.DataFrame(data=results, columns=['Score','Best Params','Max Depth'])\n",
    "optimal = results['Score'].idxmax()\n",
    "print(results.iloc[optimal])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     MAE  RMSE  Bias\n",
      "AdaBoost optimized                  \n",
      "Train               10.8  24.8   0.5\n",
      "Test                17.7  47.2   3.6\n"
     ]
    }
   ],
   "source": [
    "#Model with optimal parameters\n",
    "ada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=8),n_estimators=100,learning_rate=0.005,loss='linear')\n",
    "ada = ada.fit(X_train,Y_train)\n",
    "Y_train_pred = ada.predict(X_train)\n",
    "Y_test_pred = ada.predict(X_test)\n",
    "kpi_ML(Y_train, Y_train_pred, Y_test, Y_test_pred, name='AdaBoost optimized')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
